{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd #http://dask.pydata.org/en/latest/\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bokeh.io import output_notebook\n",
    "import fastparquet\n",
    "# from distributed import Client, progress\n",
    "\n",
    "# # Setup Dask Distributed\n",
    "# client = Client()\n",
    "# print(client)\n",
    "\n",
    "### Other Settings\n",
    "# Show more rows\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "# Prevent scientific notation of decimals\n",
    "pd.set_option('precision',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Analyzing Airline Flight Delays\n",
    "For a full treatment of the unit 14 case study, please review module 14.3. Some points from the video are given below.\n",
    "\n",
    "Work with the airline data set (use R or Python to manage out-of-core).\n",
    "Answer the following questions by using the split-apply-combine technique:\n",
    "* Which airports are most likely to be delayed flying out of or into?\n",
    "* Which flights with same origin and destination are most likely to be delayed?\n",
    "* Can you regress how delayed a flight will be before it is delayed?\n",
    "* What are the most important features for this regression?\n",
    "\n",
    "Remember to properly cross-validate models.\n",
    "\n",
    "Use meaningful evaluation criteria.\n",
    "\n",
    "Create at least one new feature variable for the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"82ef5416-39c0-4706-aa18-78b115b822af\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"82ef5416-39c0-4706-aa18-78b115b822af\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"82ef5416-39c0-4706-aa18-78b115b822af\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '82ef5416-39c0-4706-aa18-78b115b822af' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"82ef5416-39c0-4706-aa18-78b115b822af\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"82ef5416-39c0-4706-aa18-78b115b822af\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/1987.csv\", \"r\") as f:\n",
    "    for i in range(1,5):\n",
    "        print(f.readline())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ActualElapsedTime', 'AirTime', 'ArrDelay', 'ArrTime', 'CRSArrTime', 'CRSDepTime', 'CRSElapsedTime', 'CancellationCode', 'Cancelled', 'CarrierDelay', 'DayOfWeek', 'DayofMonth', 'DepDelay', 'DepTime', 'Dest', 'Distance', 'Diverted', 'FlightNum', 'LateAircraftDelay', 'Month', 'NASDelay', 'Origin', 'SecurityDelay', 'TailNum', 'TaxiIn', 'TaxiOut', 'UniqueCarrier', 'WeatherDelay', 'Year'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts = {'ActualElapsedTime': 'float64', # Confirmed\n",
    " 'AirTime': 'float64', # Confirmed\n",
    " 'ArrDelay': 'float64', # Confirmed\n",
    " 'ArrTime': 'float64', # Confirmed\n",
    " 'CRSArrTime': 'int64', # Confirmed\n",
    " 'CRSDepTime': 'int64', # Confirmed\n",
    " 'CRSElapsedTime': 'float64', # !!!!!!!!!!!!!! This one is causing an issue as an int trying float\n",
    " 'CancellationCode': 'O', # Confirmed by lesson video\n",
    " 'Cancelled': 'int64', # Confirmed\n",
    " 'CarrierDelay': 'float64', # Confirmed\n",
    " 'DayOfWeek': 'int64', # Confirmed\n",
    " 'DayofMonth': 'int64', # Confirmed\n",
    " 'DepDelay': 'float64', # Confirmed\n",
    " 'DepTime': 'float64', # Confirmed\n",
    " 'Dest': 'O', # Confirmed\n",
    " 'Distance': 'float64', # Confirmed\n",
    " 'Diverted': 'int64', # Confirmed\n",
    " 'FlightNum': 'int64', # Exploring if int or string\n",
    " 'LateAircraftDelay': 'float64', # Confirmed\n",
    " 'Month': 'int64', # Confirmed\n",
    " 'NASDelay': 'float64', # Confirmed\n",
    " 'Origin': 'O', # Confirmed\n",
    " 'SecurityDelay': 'float64', # Confirmed\n",
    " 'TailNum': 'O', # Confirmed\n",
    " 'TaxiIn': 'float64', # Confirmed\n",
    " 'TaxiOut': 'float64', # Confirmed\n",
    " 'UniqueCarrier': 'O', # Confirmed\n",
    " 'WeatherDelay': 'float64', # Confirmed\n",
    " 'Year': 'int64'} # Confirmed\n",
    "\n",
    "dts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
      "       'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'TailNum',\n",
      "       'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay',\n",
      "       'DepDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut',\n",
      "       'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay',\n",
      "       'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay'],\n",
      "      dtype='object')\n",
      "0:42:23.059454\n"
     ]
    }
   ],
   "source": [
    "# Convert csv to parquet\n",
    "def csv_to_parquet():\n",
    "    df_csv = dd.read_csv(\"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/*.csv\", \n",
    "                     usecols = dts.keys(),\n",
    "                     dtype=dts, \n",
    "                     encoding='iso-8859-1')\n",
    "    #print(df_csv.columns)\n",
    "    df_csv.dtypes.to_dict()\n",
    "\n",
    "    df_csv.to_parquet(\"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/parquet/\",\n",
    "                  compression='gzip',\n",
    "                  object_encoding='utf8')\n",
    "\n",
    "start = datetime.now()\n",
    "csv_to_parquet()\n",
    "time_to_complete = datetime.now() - start\n",
    "print(time_to_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.38432423333334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_to_complete.total_seconds()/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review of Dask \n",
    "* Ryan's Hardware: \n",
    "    - CPU: Intel i5-4300M @ 2.60GHz\n",
    "    - Disk: Samsung SSD 850 Pro\n",
    "    - RAM: 8 GB\n",
    "    \n",
    "\n",
    "* Dask using original csv:\n",
    "    - no conversion\n",
    "    - size on disk\n",
    "        - 11.2 gb\n",
    "    - benchmark of describing 'Distance':\n",
    "        - Unable to complete due to memory errors. This is surprising because this is what Dask is supposed to prevent.\n",
    "* Dask using uncompressed parquet: \n",
    "    - conversion to parquet\n",
    "        - approx 10 minutes (9.57 minutes on Ryan's laptop with SSD)\n",
    "    - size on disk:\n",
    "        - 13.8 gb\n",
    "    - benchmark of describing 'Distance':\n",
    "        - 1 loop, best of 3: 6.2 s per loop\n",
    "* Dask using gzip compressed parquet:\n",
    "    - converstion to parquet\n",
    "        - approx 42 minutes (9.57 minutes on Ryan's laptop with SSD)\n",
    "    - size on disk:\n",
    "        - 1.36 gb <- big difference\n",
    "    - benchmark of describing 'Distance':\n",
    "        - 1 loop, best of 3: 8.83 s per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_par = dd.read_parquet(\"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/parquet/\")\n",
    "#print(df_par.columns)\n",
    "#df_par.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Distance\n",
      "count  123332969.000\n",
      "mean         701.699\n",
      "std          551.253\n",
      "min            0.000\n",
      "25%          372.000\n",
      "50%          733.000\n",
      "75%         1121.000\n",
      "max         4983.000\n",
      "            Distance\n",
      "count  123332969.000\n",
      "mean         701.699\n",
      "std          551.253\n",
      "min            0.000\n",
      "25%          372.000\n",
      "50%          733.000\n",
      "75%         1121.000\n",
      "max         4983.000\n",
      "            Distance\n",
      "count  123332969.000\n",
      "mean         701.699\n",
      "std          551.253\n",
      "min            0.000\n",
      "25%          372.000\n",
      "50%          733.000\n",
      "75%         1121.000\n",
      "max         4983.000\n",
      "            Distance\n",
      "count  123332969.000\n",
      "mean         701.699\n",
      "std          551.253\n",
      "min            0.000\n",
      "25%          372.000\n",
      "50%          733.000\n",
      "75%         1121.000\n",
      "max         4983.000\n",
      "1 loop, best of 3: 8.83 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "format = lambda x: \"{0:.3f}\".format(x) \n",
    "start = datetime.now()\n",
    "print(df_par[['Distance']].dropna().describe().compute().applymap(format))\n",
    "time_to_complete = datetime.now() - start\n",
    "time_to_complete.total_seconds()/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_csv = dd.read_csv(\"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/*.csv\", \n",
    "                 usecols = dts.keys(),\n",
    "                 dtype=dts, \n",
    "                 encoding='iso-8859-1')\n",
    "print(df_csv.info())\n",
    "df_csv.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "format = lambda x: \"{0:.3f}\".format(x) \n",
    "start = datetime.now()\n",
    "print(df_csv[['Distance']].describe().compute().applymap(format))\n",
    "time_to_complete = datetime.now() - start\n",
    "time_to_complete.total_seconds()/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration to Address Variable Issues\n",
    "* CRSElapsedTime - should be an int\n",
    "* FlightNum - Alphas started to be used at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_par['FlightNum'] = df_par['FlightNum'].astype('int64')\n",
    "df_par['CRSElapsedTime'] = df_par['CRSElapsedTime'].astype('float64')\n",
    "df_par.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_numeric(x, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_par.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
    "from dask.diagnostics import visualize\n",
    "\n",
    "df_par_orgin = df_par.groupby('Origin')\n",
    "\n",
    "with Profiler() as prof, ResourceProfiler(dt=0.25) as rprof, CacheProfiler() as cprof:\n",
    "    out = df_par_orgin['DepDelay'].mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import visualize\n",
    "visualize([prof, rprof, cprof])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Regression of Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_par_samp = df_par[['ArrDelay','Distance', 'DepTime']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "ArrDelay_X = df_par[['Distance', 'DepTime']]\n",
    "\n",
    "ArrDelay_y = df_par[['ArrDelay']]\n",
    "\n",
    "reg.fit(ArrDelay_X, ArrDelay_y)\n",
    "print('Coefficients: \\n', reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ArrDelay_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
