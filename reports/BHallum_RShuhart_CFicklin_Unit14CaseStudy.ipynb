{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Analyzing Airline Flight Delays \n",
    "#### By Brett Hallum, Chris Ficklin, and Ryan Shuhart<br>April 2017\n",
    "\n",
    "For a full treatment of the unit 14 case study, please review module 14.3. Some points from the video are given below.\n",
    "\n",
    "Work with the airline data set (use R or Python to manage out-of-core).\n",
    "Answer the following questions by using the split-apply-combine technique:\n",
    "* Which airports are most likely to be delayed flying out of or into?\n",
    "* Which flights with same origin and destination are most likely to be delayed?\n",
    "* Can you regress how delayed a flight will be before it is delayed?\n",
    "* What are the most important features for this regression?\n",
    "\n",
    "Remember to properly cross-validate models.\n",
    "\n",
    "Use meaningful evaluation criteria.\n",
    "\n",
    "Create at least one new feature variable for the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd #http://dask.pydata.org/en/latest/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(set_as_default=True)\n",
    "# print(client)\n",
    "\n",
    "### Other Settings\n",
    "# Show more rows\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# Prevent scientific notation of decimals\n",
    "pd.set_option('precision',3)\n",
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"4ff206be-3a70-4dcb-a575-f3622d5470e7\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"4ff206be-3a70-4dcb-a575-f3622d5470e7\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"4ff206be-3a70-4dcb-a575-f3622d5470e7\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '4ff206be-3a70-4dcb-a575-f3622d5470e7' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"4ff206be-3a70-4dcb-a575-f3622d5470e7\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"4ff206be-3a70-4dcb-a575-f3622d5470e7\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Allow inline display of bokeh graphics\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Here is some info about Dask]...\n",
    "\n",
    "...General facts about Dask... blah blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Year</td>\n",
       "      <td>int64</td>\n",
       "      <td>1987-2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Month</td>\n",
       "      <td>int64</td>\n",
       "      <td>1 - 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DayofMonth</td>\n",
       "      <td>int64</td>\n",
       "      <td>1 - 31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DayOfWeek</td>\n",
       "      <td>int64</td>\n",
       "      <td>1 (Monday) - 7 (Sunday)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DepTime</td>\n",
       "      <td>float64</td>\n",
       "      <td>actual departure time (local, hhmm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CRSDepTime</td>\n",
       "      <td>int64</td>\n",
       "      <td>scheduled departure time (local, hhmm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ArrTime</td>\n",
       "      <td>float64</td>\n",
       "      <td>actual arrival time (local, hhmm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRSArrTime</td>\n",
       "      <td>int64</td>\n",
       "      <td>scheduled arrival time (local, hhmm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UniqueCarrier</td>\n",
       "      <td>O</td>\n",
       "      <td>unique carrier code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FlightNum</td>\n",
       "      <td>int64</td>\n",
       "      <td>flight number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TailNum</td>\n",
       "      <td>O</td>\n",
       "      <td>plane tail number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ActualElapsedTime</td>\n",
       "      <td>float64</td>\n",
       "      <td>in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CRSElapsedTime</td>\n",
       "      <td>float64</td>\n",
       "      <td>in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AirTime</td>\n",
       "      <td>float64</td>\n",
       "      <td>in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ArrDelay</td>\n",
       "      <td>float64</td>\n",
       "      <td>arrival delay, in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DepDelay</td>\n",
       "      <td>float64</td>\n",
       "      <td>departure delay, in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Origin</td>\n",
       "      <td>O</td>\n",
       "      <td>origin IATA airport code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dest</td>\n",
       "      <td>O</td>\n",
       "      <td>destination IATA airport code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Distance</td>\n",
       "      <td>float64</td>\n",
       "      <td>in miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TaxiIn</td>\n",
       "      <td>float64</td>\n",
       "      <td>taxi in time, in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TaxiOut</td>\n",
       "      <td>float64</td>\n",
       "      <td>taxi out time in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cancelled</td>\n",
       "      <td>int64</td>\n",
       "      <td>was the flight cancelled?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CancellationCode</td>\n",
       "      <td>O</td>\n",
       "      <td>reason for cancellation (A = carrier, B = weat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Diverted</td>\n",
       "      <td>int64</td>\n",
       "      <td>1 = yes, 0 = no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CarrierDelay</td>\n",
       "      <td>float64</td>\n",
       "      <td>in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WeatherDelay</td>\n",
       "      <td>float64</td>\n",
       "      <td>in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NASDelay</td>\n",
       "      <td>float64</td>\n",
       "      <td>in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SecurityDelay</td>\n",
       "      <td>float64</td>\n",
       "      <td>in minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LateAircraftDelay</td>\n",
       "      <td>float64</td>\n",
       "      <td>in minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name Data Type  \\\n",
       "var_id                                \n",
       "1                    Year     int64   \n",
       "2                   Month     int64   \n",
       "3              DayofMonth     int64   \n",
       "4               DayOfWeek     int64   \n",
       "5                 DepTime   float64   \n",
       "6              CRSDepTime     int64   \n",
       "7                 ArrTime   float64   \n",
       "8              CRSArrTime     int64   \n",
       "9           UniqueCarrier         O   \n",
       "10              FlightNum     int64   \n",
       "11                TailNum         O   \n",
       "12      ActualElapsedTime   float64   \n",
       "13         CRSElapsedTime   float64   \n",
       "14                AirTime   float64   \n",
       "15               ArrDelay   float64   \n",
       "16               DepDelay   float64   \n",
       "17                 Origin         O   \n",
       "18                   Dest         O   \n",
       "19               Distance   float64   \n",
       "20                 TaxiIn   float64   \n",
       "21                TaxiOut   float64   \n",
       "22              Cancelled     int64   \n",
       "23       CancellationCode         O   \n",
       "24               Diverted     int64   \n",
       "25           CarrierDelay   float64   \n",
       "26           WeatherDelay   float64   \n",
       "27               NASDelay   float64   \n",
       "28          SecurityDelay   float64   \n",
       "29      LateAircraftDelay   float64   \n",
       "\n",
       "                                              Description  \n",
       "var_id                                                     \n",
       "1                                               1987-2008  \n",
       "2                                                  1 - 12  \n",
       "3                                                  1 - 31  \n",
       "4                                 1 (Monday) - 7 (Sunday)  \n",
       "5                     actual departure time (local, hhmm)  \n",
       "6                  scheduled departure time (local, hhmm)  \n",
       "7                       actual arrival time (local, hhmm)  \n",
       "8                    scheduled arrival time (local, hhmm)  \n",
       "9                                     unique carrier code  \n",
       "10                                          flight number  \n",
       "11                                      plane tail number  \n",
       "12                                             in minutes  \n",
       "13                                             in minutes  \n",
       "14                                             in minutes  \n",
       "15                              arrival delay, in minutes  \n",
       "16                            departure delay, in minutes  \n",
       "17                               origin IATA airport code  \n",
       "18                          destination IATA airport code  \n",
       "19                                               in miles  \n",
       "20                               taxi in time, in minutes  \n",
       "21                               taxi out time in minutes  \n",
       "22                              was the flight cancelled?  \n",
       "23      reason for cancellation (A = carrier, B = weat...  \n",
       "24                                        1 = yes, 0 = no  \n",
       "25                                             in minutes  \n",
       "26                                             in minutes  \n",
       "27                                             in minutes  \n",
       "28                                             in minutes  \n",
       "29                                             in minutes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "var_desc = pd.read_csv(\"../ref/var_descriptions.csv\", index_col='var_id')\n",
    "var_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parquet time:  0:00:00.560609\n",
      "\n",
      "There are 30,883,750 rows\n",
      "Time to determine row count:  0:00:35.042293\n"
     ]
    }
   ],
   "source": [
    "# Data Location\n",
    "\n",
    "#parq_folder = \"../data/parquet-tiny/\"\n",
    "parq_folder = \"../data/parquet_25/\"\n",
    "#parq_folder = \"../data/parquet/\"\n",
    "\n",
    "# Load compressed Parquet format of all years ~2 sec\n",
    "start = datetime.now()\n",
    "df = dd.read_parquet(parq_folder)\n",
    "print(\"Load parquet time: \", datetime.now() - start)\n",
    "print()\n",
    "\n",
    "# Length of dask dataframe ~3 min\n",
    "start = datetime.now()\n",
    "print(\"There are {:,d} rows\".format(len(df))) #123,534,969 Matches Eric Larson\n",
    "print(\"Time to determine row count: \", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glance at Beginning and End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1,814.000</td>\n",
       "      <td>1815</td>\n",
       "      <td>CO</td>\n",
       "      <td>None</td>\n",
       "      <td>2.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>ICT</td>\n",
       "      <td>IAH</td>\n",
       "      <td>542.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1,328.000</td>\n",
       "      <td>1318</td>\n",
       "      <td>PI</td>\n",
       "      <td>None</td>\n",
       "      <td>12.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>CLT</td>\n",
       "      <td>TYS</td>\n",
       "      <td>177.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>645.000</td>\n",
       "      <td>645</td>\n",
       "      <td>CO</td>\n",
       "      <td>None</td>\n",
       "      <td>-10.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DEN</td>\n",
       "      <td>888.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1,255.000</td>\n",
       "      <td>1245</td>\n",
       "      <td>NW</td>\n",
       "      <td>None</td>\n",
       "      <td>14.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>SFO</td>\n",
       "      <td>MEM</td>\n",
       "      <td>1,807.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>800.000</td>\n",
       "      <td>800</td>\n",
       "      <td>DL</td>\n",
       "      <td>None</td>\n",
       "      <td>24.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>LAX</td>\n",
       "      <td>HNL</td>\n",
       "      <td>2,556.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayOfWeek   DepTime  CRSDepTime UniqueCarrier TailNum  \\\n",
       "0  1987     10          5 1,814.000        1815            CO    None   \n",
       "1  1987     11          2 1,328.000        1318            PI    None   \n",
       "2  1987     10          5   645.000         645            CO    None   \n",
       "3  1987     10          4 1,255.000        1245            NW    None   \n",
       "4  1987     10          7   800.000         800            DL    None   \n",
       "\n",
       "   ArrDelay  DepDelay Origin Dest  Distance  \n",
       "0     2.000    -1.000    ICT  IAH   542.000  \n",
       "1    12.000    10.000    CLT  TYS   177.000  \n",
       "2   -10.000     0.000    ORD  DEN   888.000  \n",
       "3    14.000    10.000    SFO  MEM 1,807.000  \n",
       "4    24.000     0.000    LAX  HNL 2,556.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124799</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1,225.000</td>\n",
       "      <td>1105</td>\n",
       "      <td>9E</td>\n",
       "      <td>88919E</td>\n",
       "      <td>79.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>DSM</td>\n",
       "      <td>MEM</td>\n",
       "      <td>490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124800</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1,216.000</td>\n",
       "      <td>1220</td>\n",
       "      <td>WN</td>\n",
       "      <td>N645SW</td>\n",
       "      <td>3.000</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>MCO</td>\n",
       "      <td>BUF</td>\n",
       "      <td>1,011.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124801</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>933.000</td>\n",
       "      <td>935</td>\n",
       "      <td>DL</td>\n",
       "      <td>N908DA</td>\n",
       "      <td>-11.000</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>SLC</td>\n",
       "      <td>SAN</td>\n",
       "      <td>626.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124802</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>nan</td>\n",
       "      <td>858</td>\n",
       "      <td>YV</td>\n",
       "      <td>N27185</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORD</td>\n",
       "      <td>GRR</td>\n",
       "      <td>137.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124803</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>726.000</td>\n",
       "      <td>730</td>\n",
       "      <td>AS</td>\n",
       "      <td>N581AS</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>DFW</td>\n",
       "      <td>SEA</td>\n",
       "      <td>1,660.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year  Month  DayOfWeek   DepTime  CRSDepTime UniqueCarrier TailNum  \\\n",
       "124799  2008     12          5 1,225.000        1105            9E  88919E   \n",
       "124800  2008     12          1 1,216.000        1220            WN  N645SW   \n",
       "124801  2008     12          3   933.000         935            DL  N908DA   \n",
       "124802  2008     12          7       nan         858            YV  N27185   \n",
       "124803  2008     12          2   726.000         730            AS  N581AS   \n",
       "\n",
       "        ArrDelay  DepDelay Origin Dest  Distance  \n",
       "124799    79.000    80.000    DSM  MEM   490.000  \n",
       "124800     3.000    -4.000    MCO  BUF 1,011.000  \n",
       "124801   -11.000    -2.000    SLC  SAN   626.000  \n",
       "124802       nan       nan    ORD  GRR   137.000  \n",
       "124803    -8.000    -4.000    DFW  SEA 1,660.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Last 5 rows:\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preparation and Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scaler(df, column):\n",
    "    return (df[column] - df[column].mean())/df[column].std()\n",
    "\n",
    "# Create an hour field\n",
    "# 2400 minutes from midnight reduced to 2399 then int division drops to 23\n",
    "df = df.assign(Hour=df.CRSDepTime.clip(upper=2399)//100) \n",
    "\n",
    "# Make Categories as categorical\n",
    "df = df.categorize(['DayOfWeek', 'UniqueCarrier', 'Dest', 'Origin'])\n",
    "\n",
    "# Months from 0 AD\n",
    "df['FlightAge'] = 12*df['Year']+df['Month']-1\n",
    "\n",
    "# The months from the first recorded flight is consider the approx age of the plane. \n",
    "# Unfortunately, tail numbers not tracked until 1995. \n",
    "\n",
    "# Find the first year and month of a tail numbers flight history\n",
    "tail_births = (df.groupby('TailNum')[['FlightAge']].min().reset_index()\n",
    "                 .rename(columns={'FlightAge':'FirstFlight'}))\n",
    "\n",
    "df_with_tails = dd.merge(df, tail_births, how='left', on='TailNum')\n",
    "df_with_tails['Age'] = df_with_tails['FlightAge'] - df_with_tails['FirstFlight']\n",
    "\n",
    "df_with_tails = df_with_tails.drop(['FlightAge','FirstFlight'], axis=1)\n",
    "\n",
    "\n",
    "# Scale columns for regression of all data\n",
    "df['Hour_scaled'] = scaler(df, 'Hour')\n",
    "df['Distance_scaled'] = scaler(df, 'Distance')\n",
    "\n",
    "# Scale columns for regression for after 1994\n",
    "df_with_tails['Hour_scaled'] = scaler(df_with_tails, 'Hour')\n",
    "df_with_tails['Distance_scaled'] = scaler(df_with_tails, 'Distance')\n",
    "df_with_tails['Age_scaled'] = scaler(df_with_tails, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight Delays\n",
    "\n",
    "When a schedule airflight is behind more than 15 minutes then it is officially delayed. Same logic will be followed for arrival times. Only arrivals 15 minutes past scheduled time will be considered late\n",
    "\n",
    "http://aspmhelp.faa.gov/index.php/Types_of_Delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "\n",
    "View visualization of dask distrubuted at work\n",
    "\n",
    "http://127.0.0.1:8787/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "start = datetime.now()\n",
    "# Define some aggregations to plot\n",
    "aggregations = (\n",
    "    #1 Average departure delay by year\n",
    "    df.groupby('Year').DepDelay.mean(),\n",
    "    \n",
    "    #2 Average departure delay by Month\n",
    "    df.groupby('Month').DepDelay.mean(), \n",
    "    \n",
    "    #3 Average departure delay by hour of day\n",
    "    df.groupby('Hour').DepDelay.mean(), \n",
    "    \n",
    "    #4 Average departure delay by Carrier, top 15\n",
    "    df.groupby('UniqueCarrier').DepDelay.mean().nlargest(15), \n",
    "    \n",
    "    #5 Average arrival delay by destination, top 15\n",
    "    (df.groupby('Dest').ArrDelay.mean().nlargest(15) \n",
    "     .reset_index().rename(columns={'ArrDelay':'AvgArrDelay'})),\n",
    "    \n",
    "    #6 Count of arrivals to destinations, excludes missing\n",
    "    (df.groupby('Dest').ArrDelay.count() \n",
    "     .reset_index().rename(columns={'ArrDelay':'ArrCount'})),\n",
    "    \n",
    "    #7 Average departure delay by origin, top 15\n",
    "    (df.groupby('Origin').DepDelay.mean().nlargest(15).reset_index().rename(columns={'DepDelay':'AvgDepDelay'})),\n",
    "    \n",
    "    #8 Count of departures by origin, excludes missing\n",
    "    (df.groupby('Origin').DepDelay.count().reset_index().rename(columns={'DepDelay':'DepCount'})), \n",
    "    \n",
    "    #9 Average departure by origin and destination\n",
    "    (df.groupby(['Origin','Dest']).DepDelay.mean().reset_index().rename(columns={'DepDelay':'AvgDepDelay'})),\n",
    "    \n",
    "    #10 Count of departures between origin and destination\n",
    "    (df.groupby(['Origin','Dest']).DepDelay.count().reset_index().rename(columns={'DepDelay':'DepCount'})),\n",
    "    \n",
    "    #11 Percentage of officially delayed flights by origin\n",
    "    ((df[df.DepDelay>15].groupby('Origin').DepDelay.count() / df.groupby('Origin').DepDelay.count())\n",
    "     .reset_index().rename(columns={'DepDelay':'PercDepDelay'})),\n",
    "    \n",
    "    #12 Percentage of officially late flights by destination\n",
    "    ((df[df.ArrDelay>15].groupby('Dest').ArrDelay.count() / df.groupby('Dest').ArrDelay.count())\n",
    "     .reset_index().rename(columns={'ArrDelay':'PercArrDelay'})),\n",
    "                \n",
    "    #13 Percentage of officially delayed flights by origin and destination\n",
    "    ((df[df.DepDelay>15].groupby(['Origin','Dest']).DepDelay.count() / df.groupby(['Origin','Dest']).DepDelay.count())\n",
    "     .reset_index().rename(columns={'DepDelay':'PercDepDelay'})),\n",
    "                \n",
    "    #14 Percentage of officially late flights by origin and destination\n",
    "    ((df[df.ArrDelay>15].groupby(['Origin','Dest']).ArrDelay.count() / df.groupby(['Origin','Dest']).ArrDelay.count())\n",
    "     .reset_index().rename(columns={'ArrDelay':'PercArrDelay'})),\n",
    "    \n",
    "    #15 Average departure delay by hour of day\n",
    "    df.groupby('DayOfWeek').DepDelay.mean()\n",
    ")\n",
    "\n",
    "# Compute them all in a single command\n",
    "(\n",
    "delayed_by_year, #1\n",
    "delayed_by_month, #2\n",
    "delayed_by_hour, #3\n",
    "delayed_by_carrier, #4\n",
    "delayed_by_dest, #5\n",
    "delayed_by_dest_count, #6\n",
    "delayed_by_origin, #7\n",
    "delayed_by_origin_count, #8\n",
    "delayed_by_origin_dest, #9\n",
    "delayed_by_origin_dest_count, #10\n",
    "pct_delayed_by_origin, #11\n",
    "pct_late_by_dest, #12\n",
    "pct_delayed_by_origin_dest, #13\n",
    "pct_late_by_origin_dest, #14\n",
    "delayed_by_day #15\n",
    ") = dask.compute(*aggregations)\n",
    "print(datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Average Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.charts.attributes import cat\n",
    "from bokeh.charts import Bar\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "# Average Delay by Year\n",
    "p1 = Bar(delayed_by_year.reset_index(), 'Year', values= 'DepDelay', \n",
    "         legend=False, ylabel=\"Average Delay in Minutes\", \n",
    "         title=\"Average Delay by Year\")\n",
    "\n",
    "# Average Delay by Month\n",
    "delayed_by_month = delayed_by_month.sort_index()\n",
    "p2 = Bar(delayed_by_month.reset_index(), 'Month', values= 'DepDelay', \n",
    "         legend=False, ylabel=\"Average Delay in Minutes\", \n",
    "         title=\"Average Delay by Month\")\n",
    "\n",
    "# Average Delay by Hour of Day\n",
    "p3 = Bar(delayed_by_hour.reset_index(), 'Hour', values= 'DepDelay', \n",
    "         legend=False, ylabel=\"Average Delay in Minutes\",\n",
    "         title=\"Average Delay by Hour of Day\")\n",
    "\n",
    "# Average Delay by Hour of Day\n",
    "p4 = Bar(delayed_by_day.reset_index(), 'DayOfWeek', values= 'DepDelay', \n",
    "         legend=False, ylabel=\"Average Delay in Minutes\",\n",
    "         title=\"Average Delay by Day of Week\")\n",
    "\n",
    "# Average Delay by Carrier\n",
    "delayed_by_carrier = delayed_by_carrier.reset_index()\n",
    "delayed_by_carrier['UniqueCarrier'] = delayed_by_carrier['UniqueCarrier'].astype('O')\n",
    "p5 = Bar(delayed_by_carrier, label=cat('UniqueCarrier', sort=False), values= 'DepDelay', \n",
    "         legend=False, ylabel=\"Average Delay in Minutes\", xlabel=\"Unique Carrier\", title=\"Average Delay by Carrier\")\n",
    "\n",
    "\n",
    "show(gridplot([[p1,p2],[p3,p4], [p5,None]], plot_width=400, plot_height=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Which airports are most likely to be delayed flying out of or into?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airport_delays_pcts = (pd.merge(pct_delayed_by_origin, pct_late_by_dest, left_on='Origin', right_on='Dest')\n",
    "                 .assign(AvgDelay= lambda x: (x['PercDepDelay'] + x['PercArrDelay'])/2)\n",
    "                 .sort_values(by='AvgDelay', ascending=False)\n",
    "                 .drop('Dest', axis=1)\n",
    "                )\n",
    "\n",
    "airport_delays_pcts = pd.merge(airport_delays_pcts, delayed_by_origin_count, on='Origin')\n",
    "\n",
    "airport_delays_pcts[airport_delays_pcts['DepCount'] > 50].nlargest(15, 'AvgDelay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Which flights with same origin and destination are most likely to be delayed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "org_dest_pcts = (pd.merge(pct_delayed_by_origin_dest, pct_late_by_origin_dest, on=['Origin','Dest'])\n",
    "                 .assign(AvgDelay= lambda x: (x['PercDepDelay'] + x['PercArrDelay'])/2)\n",
    "                 .sort_values(by='AvgDelay', ascending=False)\n",
    "                )\n",
    "\n",
    "org_dest_pcts = pd.merge(org_dest_pcts, delayed_by_origin_dest_count, on=['Origin','Dest'])\n",
    "\n",
    "org_dest_pcts[org_dest_pcts['DepCount'] > 50].nlargest(15, 'AvgDelay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Histogram\n",
    "\n",
    "hist = Histogram(df[df['DepDelay']>15][['DepDelay']].dropna().compute(), values='DepDelay', bins=50)\n",
    "\n",
    "show(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you regress how delayed a flight will be before it is delayed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## What are the most important features for this regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Regression of Delay\n",
    "\n",
    "The Dask module is a solution for processing \"big data,\" however, the it currently does not include built in methods for regression or classification, like other big data solutions. The following will use a series of simple random sampling to a size that fits into a pandas dataframe to find the coefficient estimates of a linear model. The coefficients will be averaged to make a final prediction. This process also assists in not over fitting the model.\n",
    "\n",
    "#### The following features will be explore to predict if the flight will have departure delay\n",
    "\n",
    "##### The predicted variable will be: \n",
    "* Departure Delay (DepDelay)\n",
    "\n",
    "##### The explanatory variables:\n",
    "* Scheduled departure hour (Hour)\n",
    "* Flight distance (Distance)\n",
    "* Age of plane (Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://adventuresindatascience.wordpress.com/2014/12/30/minibatch-learning-for-large-scale-data-using-scikit-learn/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample the entire data set as large as possible a few times. Each time has it's own cross validation sampling.\n",
    "def sample_coef(Xcols, ycol, df, samp_size = .1, seeds = [123,456,789,101,112]):\n",
    "    from sklearn import linear_model\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import r2_score\n",
    "    import dask\n",
    "    reg = linear_model.LinearRegression(n_jobs=-1)\n",
    "    coefs = []\n",
    "    \n",
    "    for i in range(len(seeds)):\n",
    "        start = datetime.now()\n",
    "        # Take a sample from all the data\n",
    "        all_cols = [ycol] + Xcols\n",
    "        Xy = df[all_cols].sample(samp_size, random_state=seeds[i]).compute().dropna(axis=0)\n",
    "        X = Xy[Xcols]\n",
    "        y = Xy[ycol].values\n",
    "\n",
    "        reg.fit(X, y)\n",
    "        #print('Coefficients: \\n', reg.coef_)\n",
    "        coefs.append(reg.coef_)\n",
    "        print(\"Time for Sample {}: \".format((i+1)), datetime.now() - start)\n",
    "        #print(datetime.now() - start)\n",
    "    \n",
    "    del Xy, X, y\n",
    "\n",
    "    coef_df = pd.DataFrame.from_records(coefs, columns=Xcols)\n",
    "    coef_avg = coef_df.mean()\n",
    "    print()\n",
    "    print(coef_df)\n",
    "    print()\n",
    "    print(\"Average Coefficients:\")\n",
    "    print(coef_avg)\n",
    "    print()\n",
    "    \n",
    "    beta_cols = []\n",
    "    for m, c in zip(coef_avg.index, coef_avg.values):\n",
    "        b_col = \"Beta_\"+m\n",
    "        df[\"Beta_\"+m] = df[m]*c\n",
    "        beta_cols.append(b_col)\n",
    "\n",
    "    df['Predicted'] = df[beta_cols].sum(axis=1)\n",
    "\n",
    "    #df['SqError'] = (df['Predicted'] - df[ycol])**2\n",
    "    #mse = df[['SqError']].mean().compute()\n",
    "    \n",
    "    df_tmp = df[['Predicted']+[ycol]].sample(.4).compute().dropna()\n",
    "    y_true = df_tmp[ycol]\n",
    "    y_pred = df_tmp['Predicted']\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(\"Mean Squared Error: \", mse)\n",
    "    print(\"R Squared: \", r2)\n",
    "    return coef_df, coef_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xcols = ['Hour', 'Distance']\n",
    "ycol =  'DepDelay'\n",
    "coef_df, coef_avg = sample_coef(Xcols, ycol, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xcols = ['Hour_scaled', 'Distance_scaled']\n",
    "ycol =  'DepDelay'\n",
    "coef_df, coef_avg = sample_coef(Xcols, ycol, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryan.shuhart\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\dask\\compatibility.py:49: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return func(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Sample 1:  0:02:03.045038\n",
      "Time for Sample 2:  0:02:12.284566\n",
      "Time for Sample 3:  0:02:08.581354\n",
      "Time for Sample 4:  0:01:59.252820\n",
      "Time for Sample 5:  0:02:00.928916\n",
      "\n",
      "   Hour  Distance   Age\n",
      "0 0.827     0.001 0.004\n",
      "1 0.827     0.001 0.004\n",
      "2 0.835     0.001 0.003\n",
      "3 0.833     0.001 0.003\n",
      "4 0.828     0.001 0.004\n",
      "\n",
      "Average Coefficients:\n",
      "Hour       0.830\n",
      "Distance   0.001\n",
      "Age        0.004\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xcols = ['Hour', 'Distance', 'Age']\n",
    "ycol =  'DepDelay'\n",
    "coef_df, coef_avg = sample_coef(Xcols, ycol, df_with_tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryan.shuhart\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\dask\\compatibility.py:49: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return func(*args)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ea40bde56936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mXcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Hour_scaled'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Distance_scaled'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Age_scaled'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mycol\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34m'DepDelay'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcoef_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_coef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mycol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_with_tails\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-d6e6c3f7711a>\u001b[0m in \u001b[0;36msample_coef\u001b[1;34m(Xcols, ycol, df, samp_size, seeds)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mycol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m#print('Coefficients: \\n', reg.coef_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mcoefs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ryan.shuhart\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 512\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ryan.shuhart\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\Users\\ryan.shuhart\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    414\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[1;32m--> 416\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "Xcols = ['Hour_scaled', 'Distance_scaled', 'Age_scaled']\n",
    "ycol =  'DepDelay'\n",
    "coef_df, coef_avg = sample_coef(Xcols, ycol, df_with_tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Dask is a new \"big data\" alternative for those preferring the Python language. Although it is in active development by Continuum.io it still lacks certain features, such as, a drop-in generalized linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "* Optimize with index key base on Data, deptarture time, and TailNum\n",
    "* Use of alternative compression, such as snappy or LZ4\n",
    "    * http://java-performance.info/performance-general-compression/\n",
    "* Use a diffent big data approach to find a more efficient way to estimating the linear model coefficients:\n",
    "    * Spark MLLib\n",
    "    * Dask GLM\n",
    "    * Turi/Graphlab Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "* Dask Documentation, http://dask.pydata.org/en/latest/\n",
    "* Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers, Boyd, et al http://stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf\n",
    "* https://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp\n",
    "* Variable Descriptions: http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "* Dask example using airline data https://jcrist.github.io/dask-sklearn-part-3.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix A - CSV to Parquet Conversion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Convert csv to parquet\n",
    "csv_folder = \"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/*.csv\"\n",
    "#parq_folder = \"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/parquet-tiny/\"\n",
    "#parq_folder = \"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/parquet/\"\n",
    "parq_folder = \"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/parquet_25/\"\n",
    "\n",
    "# Variable Metadata\n",
    "var_desc = pd.read_csv(\"../ref/var_descriptions.csv\", index_col='var_id')\n",
    "\n",
    "# Columns for Analysis\n",
    "columns = ['Year', 'Month', 'DayOfWeek', 'Origin','Dest', 'DepTime', 'CRSDepTime',\n",
    "           'DepDelay','ArrDelay', 'UniqueCarrier', 'TailNum', 'Distance']\n",
    "use_vars = var_desc[var_desc['Name'].isin(columns)]\n",
    "\n",
    "\n",
    "def csv_to_parquet(csv_folder, parq_folder):\n",
    "    start = datetime.now()\n",
    "    df_csv = dd.read_csv(csv_folder,                       \n",
    "                         usecols = use_vars['Name'],\n",
    "                         dtype=dict(use_vars[['Name','Data Type']].values), \n",
    "                         encoding='iso-8859-1')\n",
    "\n",
    "    print(df_csv.head())\n",
    "\n",
    "    # Flip to parquet\n",
    "    df_csv.sample(.25).to_parquet(parq_folder,\n",
    "                      compression='gzip',\n",
    "                      object_encoding='utf8')\n",
    "\n",
    "    time_to_complete = datetime.now() - start\n",
    "    print(time_to_complete)\n",
    "\n",
    "csv_to_parquet(csv_folder, parq_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix B - Benchmark Tests"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def benchmark_test(df):\n",
    "    format = lambda x: \"{0:.3f}\".format(x) \n",
    "    start = datetime.now()\n",
    "    print(df[['Distance']].dropna().describe().compute().applymap(format))\n",
    "    time_to_complete = datetime.now() - start\n",
    "    print(time_to_complete)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df_par = dd.read_parquet(\"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/parquet/\")\n",
    "%timeit benchmark_test(df_par)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#%timeit Using this magic causes the memory error\n",
    "df_csv = dd.read_csv(\"C:/Users/ryan.shuhart/Downloads/AirlineDelays.tar/AirlineDelays/*.csv\", \n",
    "                 usecols = var_desc['Name'],\n",
    "                 dtype=dict(var_desc[['Name','Data Type']].values), \n",
    "                 encoding='iso-8859-1')\n",
    "\n",
    "start = datetime.now()\n",
    "benchmark_test(df_csv)\n",
    "print(datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix C - Comparison of Dask Files\n",
    "* Ryan's Hardware: \n",
    "    - CPU: Intel i5-4300M @ 2.60GHz\n",
    "    - Disk: Samsung SSD 850 Pro\n",
    "    - RAM: 8 GB\n",
    "    \n",
    "\n",
    "* Dask using original csv:\n",
    "    - no conversion\n",
    "    - size on disk\n",
    "        - 11.2 gb\n",
    "    - benchmark of describing 'Distance':\n",
    "        - Approx. 4 minutes\n",
    "* Dask using uncompressed parquet: \n",
    "    - conversion to parquet\n",
    "        - approx 10 minutes\n",
    "    - size on disk:\n",
    "        - 13.8 gb\n",
    "    - benchmark of describing 'Distance':\n",
    "        - 1 loop, best of 3: 6.2 s per loop\n",
    "* Dask using gzip compressed parquet:\n",
    "    - converstion to parquet\n",
    "        - approx 42 minutes\n",
    "    - size on disk:\n",
    "        - 1.36 gb <- big difference\n",
    "    - benchmark of describing 'Distance':\n",
    "        - 1 loop, best of 3: 8.83 s per loop\n",
    "\n",
    "#### Summary\n",
    "Dask allows for out of core management of data sets. CSV files are universal, but slow to process. Converting to parquet file format, speeds up the process by a factor of 38. Using the gzip compression, reduces size on disk from 13.8gb to 1.36 or about 10% of the uncompressed size. This comes in handy for a distributed processing in a cluster since not as much network bandwidth would be needed. The trade off of compression is a 42.4% increasing in processing time, however, 3 additional seconds is hardly noticable, but might be more of an issue for other tasks. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
